# ğŸš€ Multi-Document Advanced RAG System (GenAI)

> ğŸ”¥ Retrieval-Augmented Generation (RAG) redefined: Handle **multiple document types**, maintain **chat memory**, and get **source-cited answers** in a **sleek UI**.

---

## âœ¨ The "Wow" Factor

Unlike basic Q&A bots, this system is built for **real-world enterprise use cases**:

- ğŸ“‚ Works with **PDFs, PPTs, and TXT** files  
- ğŸ§  Maintains **conversational memory**  
- ğŸ” Provides **source citations** for each response  
- ğŸ¨ Fully polished **modern UI** (Next.js + Tailwind)  

---


## ğŸ¯ Use Cases

- ğŸ“š Academic Research â€“ Upload papers & chat with citations

- ğŸ¢ Enterprise Knowledge Base â€“ Centralize documents for employees

- âš–ï¸ Legal & Compliance â€“ Search through contracts, cite sources

- ğŸ’¡ Personal Knowledge Assistant â€“ Your second brain powered by GenAI



## ğŸ–¼ï¸ Demo Screenshots

<p align="center">
  <img src="screenshots/upload.png" alt="Document Upload" width="800"/>
  <br/>
  <em>ğŸ“‚ Upload multiple document types seamlessly</em>
</p>

<p align="center">
  <img src="screenshots/chat.png" alt="Chat Interface" width="800"/>
  <br/>
  <em>ğŸ’¬ Conversational AI with memory + citations</em>
</p>

<p align="center">
  <img src="screenshots/results.png" alt="Cited Answer" width="800"/>
  <br/>
  <em>ğŸ” Responses grounded in your documents</em>
</p>

---

## ğŸ—ï¸ Tech Stack

| Layer         | Technology |
|---------------|------------|
| **Frontend**  | Next.js (React 18), Tailwind CSS |
| **Backend**   | FastAPI (Python 3.11), Docker |
| **AI Core**   | LangChain, OpenAI LLMs & Embeddings |
| **Vector DB** | Pinecone |
| **Deployment**| Vercel (Frontend), AWS EC2/Lightsail (Backend) |

---

## âš¡ Key Features

âœ… **Multi-Format Document Support** â†’ PDFs, PPTs, TXT  
âœ… **Memory-Aware Conversations** â†’ Context stays consistent across turns  
âœ… **Source-Cited Answers** â†’ Traceable, reliable responses  
âœ… **High-Performance Backend** â†’ Powered by **FastAPI** + Dockerized services  
âœ… **Modern Deployment** â†’ Scalable setup with Vercel + AWS  

---

## ğŸ”§ Installation & Setup

### 1. Clone the repo
```bash
git clone https://github.com/your-username/multi-doc-rag.git
cd multi-doc-rag
```

### 2. Backend Setup (FastAPI + LangChain) 
```bash
cd backend
pip install -r requirements.txt
uvicorn app.main:app --reload
```
### 3. Frontend Setup (Next.js)
```bash
cd frontend
npm install
npm run dev
```
### 4. Environment Variables
```bash
OPENAI_API_KEY=your_api_key
PINECONE_API_KEY=your_api_key
PINECONE_ENVIRONMENT=your_env

```
---

## ğŸ¤ Contributing

Pull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.

---


## â­ Show Your Support

If you like this project, please give it a â­ on GitHub and share it with others! ğŸš€



---

ğŸ“¬ Connect

ğŸ‘¨â€ğŸ’» Author: Yuvraj Tayal

Portfolio : [Link](https://yuvraj-portfolio-seven.vercel.app/)

ğŸ”— LinkedIn: [linkedin.com/in/yuvraj-tayal](https://www.linkedin.com/in/yuvraj-tayal-7a3a48356)

ğŸ¦ Twitter: [twitter.com/yuvrajtayal](https://x.com/YuvrajTayal)